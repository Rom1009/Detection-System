from fastapi import UploadFile
import torch
import albumentations as A
from albumentations.pytorch import ToTensorV2
from PIL import Image
import numpy as np
import io
import uuid
import torch.nn.functional as F
import mlflow
import os
from dotenv import load_dotenv
from mlflow.tracking import MlflowClient
import base64
import cv2
from .interface import IPredictService
from .model import PredictionResponse

load_dotenv()

class PredictService(IPredictService):
    
    def __init__(self):
        super().__init__()
        self.model = None
        self.model_version = "unknown"
        self.model_name = "DeepLabV3_Model_Registry"
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.load_model_direct()
        
    def load_model_direct(self):
        print(f"ğŸ”„ Äang káº¿t ná»‘i MLflow Ä‘á»ƒ load model: {self.model_name}")
        
        # 1. Cáº¥u hÃ¬nh URI
        mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI"))
        
        try:
            # 2. Láº¥y thÃ´ng tin version má»›i nháº¥t (Äá»ƒ lÆ°u vÃ o biáº¿n self.model_version thÃ´i)
            client = MlflowClient()
            # TÃ¬m model á»Ÿ giai Ä‘oáº¡n Production hoáº·c Staging, hoáº·c báº£n má»›i nháº¥t báº¥t ká»³
            versions = client.get_latest_versions(self.model_name, stages=["None", "Production"])
            
            if not versions:
                raise Exception(f"KhÃ´ng tÃ¬m tháº¥y model {self.model_name} trÃªn DagsHub")
            
            # Láº¥y báº£n má»›i nháº¥t
            latest_version = versions[0]
            self.model_version = latest_version.version
            print(f"ğŸ¯ TÃ¬m tháº¥y phiÃªn báº£n: {self.model_version} (Stage: {latest_version.current_stage})")

            model_uri = f"models:/{self.model_name}/{self.model_version}"
            
            print(f"ğŸš€ Äang load model tá»« URI: {model_uri}")
            
            # MLflow tá»± Ä‘á»™ng táº£i vá» /tmp, tá»± cache, vÃ  load vÃ o biáº¿n
            self.model = mlflow.pytorch.load_model(model_uri, map_location=self.device)
            
            self.model.to(self.device)
            self.model.eval()
            print("âœ… Model Ä‘Ã£ load thÃ nh cÃ´ng!")
            
        except Exception as e:
            print(f"âŒ Lá»—i khi load model: {e}")
            # TÃ¹y chá»n: Raise lá»—i Ä‘á»ƒ server dá»«ng láº¡i luÃ´n náº¿u khÃ´ng cÃ³ model
            raise e

    def inference(self, image, device):
        transform = A.Compose([
            A.Resize(256, 256),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2(),
        ])

        transformed = transform(image=image)
        image_tensor = transformed['image'].unsqueeze(0).to(device)

        with torch.no_grad():
            outputs = self.model(image_tensor)['out']
        
        probs = F.softmax(outputs, dim=1) 
        conf_values, predicted_mask = torch.max(probs, dim=1)
        
        # Chuyá»ƒn vá» CPU/Numpy
        predicted_mask = predicted_mask.squeeze(0).cpu().numpy().astype(np.uint8)
        confidence_map = conf_values.squeeze(0).cpu().numpy()
        
        return image, predicted_mask, confidence_map
    
    # HÃ m phá»¥ trá»£ Ä‘á»ƒ nÃ©n mask thÃ nh base64 (Fix lá»—i performance)
    def mask_to_base64(self, mask):
        # NhÃ¢n 50 Ä‘á»ƒ mask nhÃ¬n rÃµ hÆ¡n (class 1->50, 2->100...)
        _, buffer = cv2.imencode('.png', mask * 50) 
        return base64.b64encode(buffer).decode('utf-8')

    async def predict(self, file: UploadFile) -> PredictionResponse:
        label_map = { 0: "scratch", 1: "stain", 2: "oil" }
        
        if self.model is None:
            return {"error": "Model chÆ°a sáºµn sÃ ng"}

        content = await file.read()
        image = Image.open(io.BytesIO(content)).convert("RGB")
        image_np = np.array(image)
        
        _, predicted_mask, confidence_map = self.inference(image_np, self.device)
        
        # Logic tÃ­nh toÃ¡n label (Giá»¯ nguyÃªn logic cá»§a báº¡n)
        unique, counts = np.unique(predicted_mask, return_counts=True)
        mask_bg = unique != 0
        unique_obj = unique[mask_bg]
        counts_obj = counts[mask_bg]

        label_name = "no defect detected"
        if len(unique_obj) > 0:
            class_id = int(unique_obj[np.argmax(counts_obj)])
            label_name = label_map.get(class_id - 1, "unknown") 
        
        return {
            "id": str(uuid.uuid4()),
            "label": label_name,
            # QUAN TRá»ŒNG: Äá»•i tolist() thÃ nh base64 Ä‘á»ƒ khÃ´ng sáº­p server
            "mask": self.mask_to_base64(predicted_mask), 
            "confidence": float(np.mean(confidence_map)),
            "model_version": self.model_version
        }