stages:
  # Bước 1: Tạo file COCO tổng (giả sử bạn có script create_coco.py)
  data_collection:
    cmd: python backend/src/ml_pipeline/data_pipeline/data_collection.py
         --root-dir backend/public/data 
         --output-file backend/public/processed/annotations.json
    deps:
      - backend/src/ml_pipeline/data_pipeline/data_collection.py
    outs:
      - backend/public/processed/annotations.json # Output là file COCO tổng

  # Bước 2: Chia dữ liệu thành tập train/valid
  split_data:
    cmd: python backend/src/ml_pipeline/data_pipeline/split_data.py --params params.yaml
    deps:
      - backend/src/ml_pipeline/data_pipeline/split_data.py
      - backend/public/processed/annotations.json # Phụ thuộc vào kết quả của bước trên
    params:
      - split # Theo dõi các tham số trong mục 'split' của params.yaml
    outs:
      - backend/public/processed/train_ids.json
      - backend/public/processed/valid_ids.json

  main:
    cmd: python backend/src/ml_pipeline/main.py
    deps:
      - backend/src/ml_pipeline/main.py

    outs: 
      - backend/src/ml_pipeline/model/model.pth
      